{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np #Manipulação de vetores, matrizes, operações, etc.\n",
    "import pandas as pd #Visualização, organização nos DataFrames (planilhas)\n",
    "import tensorflow as tf #Machine Learning e afins\n",
    "import matplotlib.pyplot as plt #Plotagem e visualização\n",
    "\n",
    "from tensorflow import keras #API de machine learning\n",
    "from keras import Sequential #Compilador p/ RNA\n",
    "from keras.layers import Dense #Construção das camadas\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn import svm #SVM padrão\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score #Model tunning\n",
    "from sklearn.preprocessing import StandardScaler #Estandardização por escalonamento\n",
    "from sklearn.feature_selection import RFECV #Seleção por eliminação recursiva de atributos\n",
    "from sklearn.metrics import confusion_matrix #Matriz de confusão p/ discriminar os erros e acertos na rede neural\n",
    "\n",
    "from itertools import product\n",
    "sc = StandardScaler()\n",
    "plt.rcParams[\"figure.figsize\"]=14,14\n",
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funções referentes à SVM\n",
    "#Variáveis:\n",
    "#--------- x_data, y_data - vetores de entrada e vetor de rótulos de estabilidade; C - parâmetro de regularização da SVM;\n",
    "#--------- kernel - função base da SVM; cv - número de dobras para validação cruzada do Stratified K-Fold no método RFECV;\n",
    "#--------- subset - dicionário em que os subconjuntos D, PG, QG e VM estão organizados;\n",
    "#'svm_rfecv()' aplica o método RFECV aos vetores de entrada x_data, selecionando os atributos para o treinamento e teste da SVM\n",
    "\n",
    "def svm_rfecv(x_data, y_data, C, kernel, cv):\n",
    "    #Aplica-se a função 'RFECV_selected()'\n",
    "    selected_data, selected_features = RFECV_selected(x_data, y_data, kernel, C, cv)\n",
    "    \n",
    "    #Divide-se os dados em conjuntos de treinamento e teste e são misturados aleatoriamente. 30% dos dados são para teste \n",
    "    x_train, x_test, y_train, y_test = train_test_split(sc.fit_transform(selected_data), y_data, test_size=0.3, shuffle = True)\n",
    "    \n",
    "    #Instância de uma SVM com C e kernel referentes à entrada que então adequa-se ao conjunto de treino\n",
    "    clf_svm_rfecv = SVC(C=C, kernel=kernel)\n",
    "    clf_svm_rfecv.fit(x_train, y_train)\n",
    "    \n",
    "    #Retorna precisão de treino e teste e as variáveis selecionadas no método RFECV\n",
    "    return clf_svm_rfecv.score(x_train, y_train), clf_svm_rfecv.score(x_test, y_test), selected_features\n",
    "#===============================================================================================================================\n",
    "#'RFECV_selected()' função para aplicar RFECV e retornar os dados selecionados e os índices das variáveis\n",
    "def RFECV_selected(x_data, y_data, kernel, C, cv):\n",
    "    #Estimador em que o RFECV baseia a métrica de avaliação das variáveis\n",
    "    estimador = SVC(kernel=kernel, C=C)\n",
    "    \n",
    "    #Aplicação do selecionador RFECV, com remoção de 1 atributo para cada iteração do método\n",
    "    selecionador = RFECV(estimador, step=1, cv=StratifiedKFold(cv))\n",
    "    selecionador = selecionador.fit(sc.fit_transform(x_data.values), y_data)\n",
    "    \n",
    "    #Retorna os atributos selecionados e os índices da seleção\n",
    "    return x_data[x_data.columns[selecionador.get_support()]], x_data.columns[selecionador.get_support()]\n",
    "#===============================================================================================================================\n",
    "#'svm()' treina e testa uma SVM\n",
    "def svm_std(x_data, y_data, C, kernel):\n",
    "    #Divide-se os dados em conjuntos de treinamento e teste e são misturados aleatoriamente. 30% dos dados são para teste \n",
    "    x_train, x_test, y_train, y_test = train_test_split(sc.fit_transform(x_data), y_data, test_size=0.3, shuffle = True)\n",
    "    \n",
    "    #Instância de uma SVM com C e kernel referentes à entrada que então adequa-se ao conjunto de treino\n",
    "    clf_svm = SVC(C=C, kernel=kernel)\n",
    "    clf_svm.fit(x_train, y_train)\n",
    "    \n",
    "    #Retorna precisão de treino e teste\n",
    "    return clf_svm.score(x_train, y_train), clf_svm.score(x_test, y_test)\n",
    "#===============================================================================================================================\n",
    "#'saida_svm_rfecv()' aplica a função 'svm_rfecv()' para C=[10, 1, 0.1, 0.01, 0.001] em todos os subconjuntos de variáveis \n",
    "def saida_svm_rfecv(subset, y_data, kernel, cv):\n",
    "    C=[10, 1, 0.1, 0.01, 0.001]\n",
    "    \n",
    "    teste=list()\n",
    "    treino=list()\n",
    "    \n",
    "    for i in range(5):\n",
    "        acc_teste=list()\n",
    "        acc_treino=list() \n",
    "        \n",
    "        for conjuntos in subset: #Para cada índice de conjunto dentro de 'subset'\n",
    "            print('SVM de kernel {} com seleção de atributos por RFECV com {} dobras - Conjunto: {}, C = {}, \\n'.format(kernel, cv, conjuntos, C[i]))\n",
    "            \n",
    "            x_data = subset[str(conjuntos)]\n",
    "            #Aplicação da função 'svm_rfecv()'\n",
    "            treino_svm_rfecv, teste_svm_rfecv, selected_features = svm_rfecv(x_data, y_data, C[i], kernel, cv)\n",
    "            \n",
    "            print('Precisão de Treino: {}% \\nPrecisão de Teste: {}%'.format(treino_svm_rfecv*100, teste_svm_rfecv*100))\n",
    "            \n",
    "            #Armazena os resultados do conjunto\n",
    "            acc_teste.append(teste_svm_rfecv)\n",
    "            acc_treino.append(treino_svm_rfecv)\n",
    "            \n",
    "            print('Conjunto {} concluído.\\n'.format(conjuntos))\n",
    "            print('Atributos escolhidos:')\n",
    "            print(*selected_features, sep = \", \") \n",
    "            print('--'*50)\n",
    "        \n",
    "        print('Sequência concluída para C = {}'.format(C[i]))\n",
    "        print('--'*50)\n",
    "        \n",
    "        #Armazena os resultados de todos os conjuntos para dado C\n",
    "        teste.append(acc_teste)\n",
    "        treino.append(acc_treino)\n",
    "\n",
    "    return teste, treino\n",
    "#===============================================================================================================================\n",
    "#'saida_svm()' aplica a função 'svm()' para C=[10, 1, 0.1, 0.01, 0.001] em todos os conjuntos de variáveis em 'subset'\n",
    "def saida_svm(subset, y_data, kernel):\n",
    "    C=[10, 1, 0.1, 0.01, 0.001]\n",
    "    \n",
    "    teste=list()\n",
    "    treino=list()\n",
    "    \n",
    "    for i in range(5):\n",
    "        acc_teste=list()\n",
    "        acc_treino=list() \n",
    "        for conjuntos in subset:\n",
    "            print('SVM de kernel {} - Conjunto: {}, C = {}, \\n'.format(kernel, conjuntos, C[i]))\n",
    "            \n",
    "            x_data = subset[str(conjuntos)]\n",
    "            treino_svm, teste_svm = svm_std(x_data, y_data, C[i], kernel)\n",
    "            \n",
    "            print('Precisão de Treino: {}% \\nPrecisão de Teste: {}%'.format(treino_svm*100, teste_svm*100))\n",
    "            \n",
    "            acc_teste.append(teste_svm)\n",
    "            acc_treino.append(treino_svm)\n",
    "            \n",
    "            print('Conjunto {} concluído.\\n'.format(conjuntos))\n",
    "\n",
    "            print('--'*50)\n",
    "        \n",
    "        print('Sequência concluída para C = {}'.format(C[i]))\n",
    "        print('--'*50)\n",
    "        teste.append(acc_teste)\n",
    "        treino.append(acc_treino)\n",
    "    \n",
    "    return teste, treino\n",
    "#===============================================================================================================================\n",
    "#'RFECV_test()' aplica RFECV para C = [10, 1, 0.1, 0.01, 0.001] e cv = [2, 3, 4, 5] combinados, retornando uma matriz com \n",
    "#o número de atributos selecionados e o ranking de atributos para cada C e cv\n",
    "def RFECV_test(x_data,y_data):\n",
    "    C = [10, 1, 0.1, 0.01, 0.001] #i\n",
    "    cv = [2, 3, 4, 5] #k\n",
    "    n=[]\n",
    "    selected_features=[]\n",
    "    c_out=[]\n",
    "    cv_out=[]\n",
    "    \n",
    "    for i in range(5):\n",
    "        #Atribui-se C = [10, 1, 0.1, 0.01, 0.001] em C[i]\n",
    "        estimador = SVC(kernel='linear', C=C[i])\n",
    "        \n",
    "        for k in range(4):\n",
    "            #Atribui-se cv = [2, 3, 4, 5] em cv[k]\n",
    "            selecionador = RFECV(estimador, step=1, cv=StratifiedKFold(cv[k]))\n",
    "            selecionador = selecionador.fit(sc.fit_transform(x_data.values), y_data)\n",
    "            \n",
    "            #selecionador.get_support() são os índices dos atributos escolhidos\n",
    "            x_features = pd.DataFrame(x_data.columns[selecionador.get_support()])\n",
    "            \n",
    "            selected_features.append(x_features.T.iloc[0])\n",
    "            \n",
    "            n.append(x_features.T.iloc[0].size)\n",
    "            c_out.append(C[i])\n",
    "            cv_out.append(cv[k])\n",
    "    rfecv = pd.DataFrame({'Número de Atributos Selecionados': n, \n",
    "                          'Ranking de Atributos Selecionados': selected_features, \n",
    "                          'C': c_out, 'Dobras Stratified K-Fold': cv_out})\n",
    "    return rfecv.sort_values('Número de Atributos Selecionados')\n",
    "#===============================================================================================================================\n",
    "def cv_score(conjuntos, y_data, cv, figure):\n",
    "    max_score = list()\n",
    "    for conjunto in conjuntos:\n",
    "        x_data = sc.fit_transform(conjuntos[str(conjunto)])\n",
    "        estimador = SVC(kernel='linear')\n",
    "        C_range = np.logspace(-10, 1, 12)\n",
    "        \n",
    "        pontuacao = list()\n",
    "        pontuacao_std = list()\n",
    "\n",
    "        for C in C_range:\n",
    "            estimador.C = C\n",
    "            c_pontuacao = cross_val_score(estimador, x_data, y_data, cv=cv, n_jobs=-1)\n",
    "            pontuacao.append(np.mean(c_pontuacao))\n",
    "            pontuacao_std.append(np.std(c_pontuacao))\n",
    "            \n",
    "        max_score.append([conjunto, np.array(pontuacao).max(), C_range[np.array(pontuacao).argmax()], cv])\n",
    "        \n",
    "        if figure:\n",
    "            plt.figure()\n",
    "            plt.semilogx(C_range, pontuacao)\n",
    "            plt.semilogx(C_range, np.array(pontuacao) + np.array(pontuacao_std), 'b--')\n",
    "            plt.semilogx(C_range, np.array(pontuacao) - np.array(pontuacao_std), 'b--')\n",
    "            locs, labels = plt.yticks()\n",
    "            plt.yticks(locs, list(map(lambda x: \"%g\" % x, locs)))\n",
    "            plt.title('Pontuação de Validação Cruzada do Subconjunto {}'.format(conjunto))\n",
    "            plt.ylabel('Score')\n",
    "            plt.xlabel('C')\n",
    "            plt.ylim(0, 1.1)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    return pd.DataFrame(max_score, columns=['Subconjunto', 'Pontuação', 'C', 'Dobras'])\n",
    "#===============================================================================================================================        \n",
    "#Função de construção da arquitetura da RNA\n",
    "#Entradas da função: número de camadas, arquitetura, função de ativação, tamanho do vetor de entrada e número de saídas.\n",
    "def build_model(n_layers, architecture, act_func, input_shape, output):\n",
    "    model = Sequential() #Sequential do Keras é um modelo de camadas lineares de neurônios, que permite a estruturação de\n",
    "                         #redes entre as camadas.\n",
    "    model.add(Dense(architecture[0], input_dim=input_shape)) #Camada de entrada, passa-se arquitetura e tamanho do vetor de entrada\n",
    "    \n",
    "    #Seleciona-se a função de ativação dos neurônios  - unidade linear retificada, função sigmoide ou função tangente hiperbólica\n",
    "    if act_func=='relu': \n",
    "        activation=tf.nn.relu\n",
    "    elif act_func=='sigmoid':\n",
    "        activation=tf.nn.sigmoid\n",
    "    elif act_func=='tanh':\n",
    "        activation=tf.nn.tanh\n",
    "    \n",
    "    for i in range(n_layers): #Estrutura da arquitetura das camadas internas    \n",
    "        model.add(Dense(architecture[i], activation=activation))\n",
    "    model.add(Dense(output, activation='sigmoid')) #Camada de saída\n",
    "    return model #Retorna o modelo construído com as entradas da função build_model()\n",
    "#===============================================================================================================================\n",
    "\n",
    "def compile_train_model(model, x_train, y_train, lr, batch_size, epochs, verbose, callbacks):\n",
    "    model_copy = model\n",
    "    \n",
    "    model_copy.compile(optimizer=SGD(lr=lr),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    model_copy.fit(x_train, y_train, epochs=epochs, validation_split=0.175, batch_size=batch_size\n",
    "                   , verbose=verbose, callbacks=callbacks)\n",
    "    return model_copy\n",
    "#===============================================================================================================================\n",
    "def plot_loss_acc(model, target_acc, title, tag1, tag2):\n",
    "    e=np.array(model.history.epoch)+1\n",
    "    l=np.array(model.history.history['loss'])\n",
    "    a=np.array(model.history.history['acc'])\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    plt.rcParams.update({'font.size': 13})\n",
    "    plt.title(title)\n",
    "    color = 'tab:blue'\n",
    "    \n",
    "    ax1.set_xlabel('Época')\n",
    "    ax1.set_ylabel('Precisão do Modelo', color=color)\n",
    "    ax1.plot(e, a, color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('Perda do Modelo', color=color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(e, l, color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    fig.savefig('loss_acc_{}_{}.png'.format(tag1, tag2))\n",
    "    plt.close()\n",
    "#===============================================================================================================================\n",
    "def eval_model(model, x_train, y_train, x_test, y_test):\n",
    "    eval_train = model.evaluate(x_train, y_train)\n",
    "    eval_test = model.evaluate(x_test, y_test)\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = (y_pred>0.5)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred) \n",
    "    \n",
    "    print('\\nPré-Classificador\\n')\n",
    "    print('Acertos - Casos Estáveis: {}, Casos Instáveis: {}\\n\\\n",
    "Erros - Falsa Estabilidade: {}, Falsa Instabilidade: {}\\n'.format(cm[0][0],cm[1][1],cm[0][1],cm[1][0]))\n",
    "    print('Precisão de Treino: {}%\\nPrecisão de Teste: {}%'.format(eval_train[1]*100,eval_test[1]*100))\n",
    "    \n",
    "    return cm[0][1], eval_test[1]*100\n",
    "#===============================================================================================================================    \n",
    "def train_test_loop(x_data_norm, y_data, dataset, plot):                              \n",
    "    print('Executando loop para o conjunto {}'.format(dataset))\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data_norm, y_data, \n",
    "                                                    test_size=0.3, \n",
    "                                                    shuffle = True)\n",
    "    n_layers = [1,2,3,4]\n",
    "    acc_desired = [0.92,0.95,0.98]\n",
    "    architecture = {'1':[[16],[32],[64],[128]],\n",
    "                    '2':[[16,8],[32,16],[64,32],[128,64]],\n",
    "                    '3':[[16,8,4],[32,16,8],[64,32,16],[128,64,32]],\n",
    "                    '4':[[16,8,4,2],[32,16,8,4],[64,32,16,8],[128,64,32,16]]}\n",
    "    cases = []\n",
    "    \n",
    "    for i in range(np.size(n_layers)):\n",
    "        cases.append(list(product(acc_desired,architecture[str(n_layers[i])])))\n",
    "        \n",
    "    print('Iniciando Treinamento com {} casos de {} variáveis'.format(x_train.shape[0], x_train.shape[1]))\n",
    "    melhores_treinos = []\n",
    "    melhor_caso = []\n",
    "    h=0\n",
    "    for n in range(np.size(n_layers)):\n",
    "        epocas, acc, arquitetura = [], [], []\n",
    "        for i,c in enumerate(cases[n]):\n",
    "            class callback(keras.callbacks.Callback):\n",
    "                def __init__(self, c, acc_threshold, print_msg):\n",
    "                    self.acc_threshold = acc_threshold\n",
    "                    self.print_msg = print_msg\n",
    "                def on_epoch_end(self, epoch, logs={}):\n",
    "                    if(logs.get('acc')>self.acc_threshold):\n",
    "                        if self.print_msg:\n",
    "                            print('\\nAtingiu {}% de precisão na {}ª época - cancelando treino...\\n'.format(c[0]*100, \n",
    "                                                                                               np.size(model.history.epoch)+1))\n",
    "                            self.model.stop_training=True\n",
    "                        else:\n",
    "                            if self.print_msg:\n",
    "                                print('\\nPrecisão insuficiente - começando nova época\\n')\n",
    "                                print(\"-\"*120)\n",
    "            #print(\"Precisão Alvo: {}%\\nNº de Camadas: {}\\nArquitetura da Rede Neural: {}\\n\".format(c[0]*100,n+1,c[1]))\n",
    "            callbacks = callback(c, acc_threshold=c[0], print_msg=True)\n",
    "            model = build_model(n_layers=n, architecture=c[1], act_func='relu',\n",
    "                                input_shape=x_train.shape[1], output=1)\n",
    "            model = compile_train_model(model, x_train, y_train, lr=0.001, \n",
    "                                        batch_size=64, epochs=150, verbose=0, callbacks=[callbacks])\n",
    "            if plot:\n",
    "                title = \"Perda e precisão por época -\\\n",
    "Precisão Alvo: {}%,\\\n",
    "Nº de Camadas: {},\\\n",
    "Arquitetura da Rede Neural: {}\".format(c[0]*100,n+1,c[1])\n",
    "                plot_loss_acc(model,target_acc=c[0],title=title, tag1=h, tag2=dataset)\n",
    "                \n",
    "            h=h+1\n",
    "            \n",
    "            avaliar_modelo, precisao_teste = eval_model(model, x_train, y_train, x_test, y_test)\n",
    "            \n",
    "            epocas.append(np.size(model.history.epoch))\n",
    "            acc.append(precisao_teste)\n",
    "            arquitetura.append(c[1])\n",
    "            \n",
    "            if avaliar_modelo == 0:\n",
    "                melhor_caso.append('Melhor Caso: {} falsa estabilidade - Dataset: {}, {} Camadas, Arquitetura {}.\\n'.format(avaliar_modelo, dataset, n+1, c[1]))\n",
    "\n",
    "            print('\\nDataset: {} - Arquitetura: {}\\n'.format(dataset, c[1]))\n",
    "            print(\"-\"*70)\n",
    "        melhores_treinos.append('Dataset: {} - Melhor Treino p/ {} Camada(s): {} Épocas com arquitetura {} e precisão de {}%.\\n'.format(dataset,n+1,\n",
    "                                                                                     np.amin(epocas),\n",
    "                                                                                     arquitetura[np.argmin(epocas)],\n",
    "                                                                                     acc[np.argmin(epocas)]))\n",
    "    return melhores_treinos, melhor_caso\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_loop_no_threshold(x_data_norm, y_data, dataset, plot, epochs):                              \n",
    "    print('Executando loop para o conjunto {}'.format(dataset))\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data_norm, y_data, \n",
    "                                                    test_size=0.3, \n",
    "                                                    shuffle = True)\n",
    "    n_layers = [1,2,3,4]\n",
    "    acc_desired = [1]\n",
    "    architecture = {'1':[[16],[32],[64],[128]],\n",
    "                    '2':[[16,8],[32,16],[64,32],[128,64]],\n",
    "                    '3':[[16,8,4],[32,16,8],[64,32,16],[128,64,32]],\n",
    "                    '4':[[16,8,4,2],[32,16,8,4],[64,32,16,8],[128,64,32,16]]}\n",
    "    cases = []\n",
    "    \n",
    "    for i in range(np.size(n_layers)):\n",
    "        cases.append(list(product(acc_desired,architecture[str(n_layers[i])])))\n",
    "        \n",
    "    print('Iniciando Treinamento com {} casos de {} variáveis'.format(x_train.shape[0], x_train.shape[1]))\n",
    "    melhores_treinos = []\n",
    "    melhor_caso = []\n",
    "    h=0\n",
    "    for n in range(np.size(n_layers)):\n",
    "        epocas, acc, arquitetura = [], [], []\n",
    "        for i,c in enumerate(cases[n]):\n",
    "            \n",
    "            model = build_model(n_layers=n, architecture=c[1], act_func='relu',\n",
    "                                input_shape=x_train.shape[1], output=1)\n",
    "            model = compile_train_model_no_threshold(model, x_train, y_train, lr=0.001, \n",
    "                                        batch_size=64, epochs=epochs, verbose=0)\n",
    "            \n",
    "            if plot:\n",
    "                title = \"Perda e precisão por época -\\\n",
    "Precisão Alvo: {}%,\\\n",
    "Nº de Camadas: {},\\\n",
    "Arquitetura da Rede Neural: {}\".format(c[0]*100,n+1,c[1])\n",
    "                plot_loss_acc(model,target_acc=c[0],title=title, tag1=h, tag2=dataset)\n",
    "                \n",
    "            h=h+1\n",
    "            \n",
    "            avaliar_modelo, precisao_teste = eval_model(model, x_train, y_train, x_test, y_test)\n",
    "            \n",
    "            epocas.append(np.size(model.history.epoch))\n",
    "            acc.append(precisao_teste)\n",
    "            arquitetura.append(c[1])\n",
    "            \n",
    "            if avaliar_modelo == 0:\n",
    "                melhor_caso.append('Melhor Caso: {} falsa estabilidade - Dataset: {}, {} Camadas, Arquitetura {}.\\n'.format(avaliar_modelo, dataset, n+1, c[1]))\n",
    "\n",
    "            print('\\nDataset: {} - Arquitetura: {}\\n'.format(dataset, c[1]))\n",
    "            print(\"-\"*70)\n",
    "        melhores_treinos.append('Dataset: {} - Melhor Treino p/ {} Camada(s): {} Épocas com arquitetura {} e precisão de {}%.\\n'.format(dataset,n+1,\n",
    "                                                                                     np.amin(epocas),\n",
    "                                                                                     arquitetura[np.argmin(epocas)],\n",
    "                                                                                     acc[np.argmin(epocas)]))\n",
    "    return melhores_treinos, melhor_caso\n",
    "\n",
    "def compile_train_model_no_threshold(model, x_train, y_train, lr, batch_size, epochs, verbose):\n",
    "    model_copy = model\n",
    "    \n",
    "    model_copy.compile(optimizer=SGD(lr=lr),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    model_copy.fit(x_train, y_train, epochs=epochs, validation_split=0.175, batch_size=batch_size, verbose=verbose)\n",
    "    return model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================================================================\n",
    "#A função 'saida_svm()' tem como saída duas tabelas constrúidas a partir da função 'svm()' para cinco valores de C\n",
    "def tabelas_svm(subset, y):\n",
    "    result_treino = list()\n",
    "    result_teste = list()\n",
    "    \n",
    "    C = [10, 1, 0.1, 0.01, 0.001]\n",
    "    for i in range(4):\n",
    "        temp=svm(subset, y, C[i], 'linear')\n",
    "        result_treino.append(temp[0])\n",
    "        result_teste.append(temp[1])\n",
    "    \n",
    "    svm_resultado_teste = pd.DataFrame({'Precisão de Teste (%), C=10': result_teste[0],\n",
    "                                        'Precisão de Teste (%), C=1': result_teste[1],\n",
    "                                        'Precisão de Teste (%), C=0.1': result_teste[2],\n",
    "                                        'Precisão de Teste (%), C=0.01': result_teste[3],\n",
    "                                        'Precisão de Teste (%), C=0.001': result_teste[4]},\n",
    "                                       index = index) #Construção da tabela de resultados da SVM para teste\n",
    "\n",
    "    svm_resultado_treino = pd.DataFrame({'Precisão de Treino (%), C=10': result_treino[0],\n",
    "                                    'Precisão de Treino (%), C=1': result_treino[0],\n",
    "                                     'Precisão de Treino (%), C=0.1': result_treino[0],\n",
    "                                     'Precisão de Treino (%), C=0.01': result_treino[0],\n",
    "                                     'Precisão de Treino (%), C=0.001': result_treino[0]}, index = index) #Construção da tabela de resultados da SVM para treino\n",
    "    #p/ resultado percentual\n",
    "    svm_resultado_treino = svm_resultado_treino.apply(lambda x: x*100)\n",
    "    svm_resultado_teste = svm_resultado_teste.apply(lambda x: x*100)\n",
    "    \n",
    "    return svm_resultado_treino, svm_resultado_teste\n",
    "\n",
    "def tabelas_svm_rfecv(teste, treino):\n",
    "\n",
    "    \n",
    "    svm_resultado_teste = pd.DataFrame({'Precisão de Teste (%), C=10': result_teste[0],\n",
    "                                        'Precisão de Teste (%), C=1': result_teste[1],\n",
    "                                        'Precisão de Teste (%), C=0.1': result_teste[2],\n",
    "                                        'Precisão de Teste (%), C=0.01': result_teste[3],\n",
    "                                        'Precisão de Teste (%), C=0.001': result_teste[4]},\n",
    "                                       index = index) #Construção da tabela de resultados da SVM para teste\n",
    "\n",
    "    svm_resultado_treino = pd.DataFrame({'Precisão de Treino (%), C=10': result_treino[0],\n",
    "                                    'Precisão de Treino (%), C=1': result_treino[1],\n",
    "                                     'Precisão de Treino (%), C=0.1': result_treino[2],\n",
    "                                     'Precisão de Treino (%), C=0.01': result_treino[3],\n",
    "                                     'Precisão de Treino (%), C=0.001': result_treino[4]}, index = index) #Construção da tabela de resultados da SVM para treino\n",
    "    #p/ resultado percentual\n",
    "    svm_resultado_treino = svm_resultado_treino.apply(lambda x: x*100)\n",
    "    svm_resultado_teste = svm_resultado_teste.apply(lambda x: x*100)\n",
    "    \n",
    "    return svm_resultado_treino, svm_resultado_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_optimal(conjuntos, y_data, cv):\n",
    "    result_test = pd.DataFrame()\n",
    "    result_train = pd.DataFrame()\n",
    "    for conjunto in conjuntos:\n",
    "        x_data = conjuntos[str(conjunto)]\n",
    "        estimador = SVC(kernel='linear')\n",
    "        C_range = np.logspace(-10, 1, 12)\n",
    "        \n",
    "        pontuacao = list()\n",
    "        pontuacao_std = list()\n",
    "\n",
    "        for C in C_range:\n",
    "            estimador.C = C\n",
    "            c_pontuacao = cross_val_score(estimador, x_data, y_data, cv=cv, n_jobs=-1)\n",
    "            pontuacao.append(np.mean(c_pontuacao))\n",
    "            pontuacao_std.append(np.std(c_pontuacao))\n",
    "        \n",
    "        acc_treino, acc_teste = SVM_RFECV(x_data, y_data, C=C_range[np.array(pontuacao).argmax()], cv=cv)\n",
    "        result_test.append(pd.DataFrame({'Precisão de Teste (%)': acc_teste, 'C': C_range[np.array(pontuacao).argmax()]/100},\n",
    "                                         index = index))\n",
    "        result_train.append(pd.DataFrame({'Precisão de Treino (%)': acc_treino, 'C': C_range[np.array(pontuacao).argmax()]/100}, \n",
    "                                         index = index))\n",
    "    \n",
    "    result_train = result_train.apply(lambda x: x*100)\n",
    "    result_test = result_test.apply(lambda x: x*100)\n",
    "    return result_train, result_test      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
